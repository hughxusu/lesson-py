# 数据分析综合实践

数据来源：[Netflix 电影与电视节目数据](https://www.kaggle.com/datasets/shivamb/netflix-shows/data)

任务目标：利用Python对Netflix平台的内容库进行深度清洗、统计与可视化，分析其全球化策略、内容偏好及时间演变趋势。

## 数据概览

1. 数据导入与概览：读取CSV文件，输出数据的维度（行数、列数）、列名、各列的数据类型，并显示前 5 行数据以了解数据结构。

```python
import pandas as pd

file_path = './netflix_titles.csv'
df = pd.read_csv(file_path)

print("数据维度:")
print(f"行数: {df.shape[0]}")
print(f"列数: {df.shape[1]}")
print()

print("列名:")
print(df.columns.tolist())
print()

print("各列数据类型:")
print(df.dtypes)
print()

print("前5行数据:")
print(df.head())
```

2. 缺失值统计与可视化：计算每一列的缺失值数量及缺失比例。使用 seaborn 绘制热力图（Heatmap）可视化缺失值的分布情况。

```python
import seaborn as sns
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

missing_values = df.isnull().sum()
print('缺失值数量:')
print(missing_values)
print()

missing_percentage = (df.isnull().sum() / df.shape[0]) * 100
print('缺失值比例 (%):')
print(round(missing_percentage, 2))
print()

plt.figure(figsize=(12, 8))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('缺失值分布热力图')
plt.savefig('missing_values_heatmap.png')
plt.show()
```

3. 缺失值处理策略：
   1. 对于country（国家）、cast（演员）、director（导演）列的缺失值，填充为"Unknown"。
   2. 对于 rating（分级）、duration（时长）列的缺失值，如果数量极少（<1%），则直接删除对应的行。


```python
print("原始数据信息:")
print(f"数据形状: {df.shape}")
print()

print("各列缺失值情况:")
missing_values = df.isnull().sum()
missing_percentage = (df.isnull().sum() / df.shape[0]) * 100
missing_df = pd.DataFrame({'缺失值数量': missing_values, '缺失比例(%)': round(missing_percentage, 2)})
print(missing_df)
print()

print("对country、cast、director列的缺失值填充为\"Unknown\"")
fill_columns = ['country', 'cast', 'director']
df[fill_columns] = df[fill_columns].fillna('Unknown')

print("填充后这三列的缺失值情况:")
print(df[fill_columns].isnull().sum())
print()

print("检查rating和duration列的缺失值比例:")
print(f"rating列缺失比例: {round((df['rating'].isnull().sum() / df.shape[0]) * 100, 2)}%")
print(f"duration列缺失比例: {round((df['duration'].isnull().sum() / df.shape[0]) * 100, 2)}%")
print()

drop_columns = ['rating', 'duration']
for col in drop_columns:
    missing_pct = (df[col].isnull().sum() / df.shape[0]) * 100
    if missing_pct < 1:
        print(f"删除{col}列中的缺失值行...")
        df = df.dropna(subset=[col])
        print(f"删除后数据形状: {df.shape}")
    else:
        print(f"{col}列缺失比例({round(missing_pct, 2)}%)超过1%，不进行删除操作")

print()

print("处理后的数据信息:")
print(f"数据形状: {df.shape}")
print()
print("处理后各列缺失值情况:")
missing_values_after = df.isnull().sum()
missing_percentage_after = (df.isnull().sum() / df.shape[0]) * 100
missing_df_after = pd.DataFrame({'缺失值数量': missing_values_after, '缺失比例(%)': round(missing_percentage_after, 2)})
print(missing_df_after)

output_path = '/Users/hughxusu/projects/lessons/lesson-py/codes/27-数据分析/netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)
print(f"\n处理后的数据已保存到: {output_path}")
```

4. 时间类型转换：将date_added（上架日期）列转换为标准的datetime格式。如果是无法解析的格式，需进行清洗或处理异常值。

```python
print("原始数据信息:")
print(f"数据形状: {df.shape}")
print()

print("date_added列的基本信息:")
print(f"数据类型: {df['date_added'].dtype}")
print(f"非空值数量: {df['date_added'].count()}")
print(f"缺失值数量: {df['date_added'].isnull().sum()}")
print()

print("date_added列的示例值:")
print(df['date_added'].dropna().head(10))
print()

print("处理缺失值...")
df['date_added'] = df['date_added'].fillna('Unknown')
print(f"填充后date_added列非空值数量: {df['date_added'].count()}")
print(f"填充后date_added列值为'Unknown'的数量: {df[df['date_added'] == 'Unknown'].shape[0]}")
print()

print("将date_added列转换为datetime格式...")
df['date_added'] = pd.to_datetime(df['date_added'], format='%d-%b-%y', errors='coerce')

print(f"转换后date_added列数据类型: {df['date_added'].dtype}")
print(f"转换后有效datetime值数量: {df['date_added'].count()}")
print(f"转换后NaT值数量: {df['date_added'].isna().sum()}")
print()

print("4. 转换后的date_added列示例值:")
print(df['date_added'].dropna().head(10))
print()

output_path = '/Users/hughxusu/projects/lessons/lesson-py/codes/27-数据分析/netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)
print("\n转换完成！")
```

5. 时间特征提取：从date_added中提取年份和月份，分别创建两个新列year_added（上架年份）和month_added（上架月份）。

```python
print("原始数据信息:")
print(f"数据形状: {df.shape}")
print()

print("date_added列的数据类型:")
print(f"数据类型: {df['date_added'].dtype}")
print()

print("确保date_added列是datetime格式...")
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')
print(f"转换后数据类型: {df['date_added'].dtype}")
print()

print("从date_added中提取年份和月份...")
df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month
print()

print("新创建的year_added和month_added列:")
print(df[['date_added', 'year_added', 'month_added']].head(10))
print()

print("新列的基本信息:")
print(f"year_added数据类型: {df['year_added'].dtype}")
print(f"month_added数据类型: {df['month_added'].dtype}")
print(f"year_added非空值数量: {df['year_added'].count()}")
print(f"month_added非空值数量: {df['month_added'].count()}")
print()

output_path = './netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)
print(f"\n更新后的数据已保存到: {output_path}")
print("提取年份和月份完成！")
```

## 数据清洗

1. 时长单位清洗与标准化：duration列包含"90 min"和"1 Season"两种格式。请拆分该列，创建两个新列：

   * duration_num：提取数值部分（整数）。

   - duration_unit：提取单位部分（清洗为 'min' 或 'season'）。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

def process_duration(row):
    parts = row.split()
    if len(parts) >= 2:
        num = int(parts[0])
        unit = parts[1].lower()
        # 标准化单位
        if 'min' in unit:
            unit = 'min'
        elif 'season' in unit:
            unit = 'season'
        else:
            unit = 'unknown'
        return num, unit
    else:
        return 0, 'unknown'

df[['duration_num', 'duration_unit']] = df['duration'].apply(
    lambda x: pd.Series(process_duration(x))
)

print("标准化后的duration_unit列示例:")
print(df['duration_unit'].value_counts())
print()

print("新创建的duration_num和duration_unit列:")
print(df[['duration', 'duration_num', 'duration_unit']].head(5))
print()

output_path = './netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)

print(f"duration_num缺失值数量: {df['duration_num'].isna().sum()}")
print(f"duration_unit缺失值数量: {df['duration_unit'].isna().sum()}")
print(f"duration_unit为'unknown'的数量: {df[df['duration_unit'] == 'unknown'].shape[0]}")
```

2. 内容分类二值化：针对type列（Movie/TV Show），将其转换为数值编码`Movie=0, TV Show=1`。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

print("原始type列分布:")
print(df['type'].value_counts())
print()

print("原始type列示例:")
print(df['type'].head(5))
print()

df['type_encoded'] = df['type'].map({'Movie': 0, 'TV Show': 1})

print("二值化后的type_encoded列分布:")
print(df['type_encoded'].value_counts())
print()

print("转换后的type和type_encoded列示例:")
print(df[['type', 'type_encoded']].head(5))
print()

output_path = './netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)

print("数据质量验证:")
print(f"type_encoded数据类型: {df['type_encoded'].dtype}")
print(f"type_encoded非空值数量: {df['type_encoded'].count()}")
print(f"type_encoded缺失值数量: {df['type_encoded'].isna().sum()}")
print()
```

3. 多值列处理（国家）：country列中很多内容涉及多个国家（如 "United States, India"）。请编写函数，仅提取第一个国家作为主制作国家，存入新列primary_country。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

print("原始country列中包含多个国家的示例:")
multi_country = df[df['country'].str.contains(',', na=False)]
print(multi_country['country'].head(5))
print()

def extract_primary_country(country_str):
    if pd.isna(country_str) or country_str.strip() == '':
        return 'Unknown'
    return country_str.split(',')[0].strip()

df['primary_country'] = df['country'].apply(extract_primary_country)

print("主制作国家分布（前20个）:")
print(df['primary_country'].value_counts().head(5))
print()

output_path = './netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)

print("数据质量验证:")
print(f"primary_country数据类型: {df['primary_country'].dtype}")
print(f"primary_country非空值数量: {df['primary_country'].count()}")
print(f"primary_country唯一值数量: {df['primary_country'].nunique()}")
print(f"primary_country为'Unknown'的数量: {df[df['primary_country'] == 'Unknown'].shape[0]}")
```

4. 多值列展开（类型标签）：listed_in 列包含多个题材标签。请统计包含标签数量最多的前 5 部影片，并计算整个数据集中所有影片平均拥有的标签数量。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

df['tag_count'] = df['listed_in'].str.split(',').apply(len)
top_tagged_movies = df.sort_values('tag_count', ascending=False).head(5)
average_tags = df['tag_count'].mean()

print("标签数量最多的前5部影片：")
for index, row in top_tagged_movies.iterrows():
    print(f"标题: {row['title']} | 类型: {row['type']} | 标签数量: {row['tag_count']} | 标签: {row['listed_in']}")

print(f"\n所有影片平均拥有的标签数量: {average_tags:.2f}")

print("\n数据质量验证:")
print(f"tag_count数据类型: {df['tag_count'].dtype}")
print(f"tag_count非空值数量: {df['tag_count'].count()}")
print(f"标签数量范围: {df['tag_count'].min()} - {df['tag_count'].max()}")
```

5. 上架滞后性分析：创建一个新列lag_years，计算公式为year_added减去release_year（上映年份）。若结果为负数，将其修正为0（视为同年上架）

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

df['lag_years'] = df['year_added'] - df['release_year']
df['lag_years'] = df['lag_years'].apply(lambda x: max(0, x))

print("上架滞后性分析结果（前10行）：")
print(df[['title', 'type', 'release_year', 'year_added', 'lag_years']].head(5))

print("\n上架滞后性统计：")
print(f"平均上架滞后年数: {df['lag_years'].mean():.2f}")
print(f"最大上架滞后年数: {df['lag_years'].max()}")
print(f"最小上架滞后年数: {df['lag_years'].min()}")
print(f"同年上架的影片数量: {df[df['lag_years'] == 0].shape[0]}")
print(f"滞后上架的影片数量: {df[df['lag_years'] > 0].shape[0]}")

output_path = './netflix_titles_cleaned.csv'
df.to_csv(output_path, index=False)
print(f"\n数据已保存到 {output_path}")
```

## 统计分析

1. 统计Movie和TV Show的数量，并计算各自的百分比，使用matplotlib绘制饼图（Pie Chart）展示两者比例，需标注百分比数值。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

print("原始类型分布:")
print(df['type'].value_counts())
print()

type_counts = df['type'].value_counts()
type_percentages = (type_counts / type_counts.sum()) * 100

print("类型分布统计:")
for type_name, count in type_counts.items():
    percentage = type_percentages[type_name]
    print(f"{type_name}: {count} 部 ({percentage:.2f}%)")

fig, ax = plt.subplots(figsize=(8, 6))
colors = ['#FF9999', '#66B2FF']

explode = (0.05, 0.05)  
wedges, texts, autotexts = ax.pie(type_counts.values,
                                  explode=explode,
                                  labels=type_counts.index,
                                  colors=colors,
                                  autopct='%1.1f%%',
                                  shadow=True,
                                  startangle=90,
                                  textprops={'fontsize': 14})

for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontsize(16)
    autotext.set_fontweight('bold')

ax.set_title('Netflix内容类型分布', fontsize=18, fontweight='bold', pad=20)
ax.axis('equal')
plt.legend(wedges, type_counts.index, title="类型", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1), fontsize=12)
plt.tight_layout()
plt.show()
```

2. 国家产出排行：基于清洗后的 primary_country 列，统计内容数量最多的前10个国家。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

top_10_countries = df[df['primary_country'] != 'Unknown']['primary_country'].value_counts().head(10)
total_without_unknown = top_10_countries.sum()
country_percentages = (top_10_countries / total_without_unknown) * 100

print("内容数量最多的前10个国家：")
print("-" * 60)
print(f"{'国家':<20} {'内容数量':<15} {'占比':<10}")
print("-" * 60)

for i, (country, count) in enumerate(top_10_countries.items(), 1):
    percentage = country_percentages[country]
    print(f"{i}. {country:<18} {count:<15} {percentage:.2f}%")

print("-" * 60)
print(f"{'合计':<20} {total_without_unknown:<15} 100.00%")

fig, ax = plt.subplots(figsize=(12, 8))
bars = ax.bar(range(len(top_10_countries)), top_10_countries.values, color='#4CAF50')
ax.set_xticks(range(len(top_10_countries)))
ax.set_xticklabels(top_10_countries.index, rotation=45, ha='right')

for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 10,
            f'{int(height)}',
            ha='center', va='bottom')

ax.set_title('Netflix内容数量最多的前10个国家', fontsize=16, fontweight='bold', pad=20)
ax.set_xlabel('国家', fontsize=14)
ax.set_ylabel('内容数量', fontsize=14)
ax.yaxis.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()
```

3. 年份趋势分析：统计每一年（year_added）上架的内容总数。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

year_counts = df['year_added'].value_counts().sort_index()

print("每一年上架的内容总数：")
print("-" * 40)
print(f"{'年份':<10} {'内容数量':<15}")
print("-" * 40)

for year, count in year_counts.items():
    print(f"{int(year):<10} {count:<15}")

print("-" * 40)
print(f"{'总计':<10} {year_counts.sum():<15}")

fig, ax = plt.subplots(figsize=(14, 8))
years = [int(year) for year in year_counts.index]
ax.plot(years, year_counts.values, marker='o', linewidth=2, markersize=8, color='#2196F3')
for i, (year, count) in enumerate(zip(years, year_counts.values)):
    ax.text(year, count + 30, f'{count}', ha='center', va='bottom', fontsize=11)
ax.set_title('Netflix每年上架内容数量趋势', fontsize=18, fontweight='bold', pad=20)
ax.set_xlabel('上架年份', fontsize=14)
ax.set_ylabel('内容数量', fontsize=14)
ax.set_xticks(years)
ax.set_xticklabels(years, rotation=45)
ax.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()
```

4. 热门分级统计：统计不同分级（rating，如TV-MA, PG-13 等）的内容数量，并按数量降序排列。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

print("热门分级统计：")
print("-" * 40)
rating_counts = df['rating'].value_counts().sort_values(ascending=False)

print(f"{'分级':<15} {'内容数量':<15} {'百分比':<10}")
print("-" * 40)

for rating, count in rating_counts.items():
    percentage = (count / rating_counts.sum()) * 100
    print(f"{rating:<15} {count:<15} {percentage:.2f}%")

print("-" * 40)
print(f"{'总计':<15} {rating_counts.sum():<15} 100.00%")

plt.figure(figsize=(14, 8))
ax = rating_counts.plot(kind='bar', color='#FF5733', alpha=0.8)
plt.title('Netflix内容分级分布', fontsize=18, fontweight='bold', pad=20)
plt.xlabel('分级', fontsize=14)
plt.ylabel('内容数量', fontsize=14)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', linestyle='--', alpha=0.7)

for i, v in enumerate(rating_counts.values):
    ax.text(i, v + 10, str(v), ha='center', fontweight='bold')

plt.tight_layout()
plt.show()
```

5. 最勤劳的导演：统计 director 列（需排除 "Unknown"），找出执导作品数量最多的前 10 位导演。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

filtered_df = df[df['director'] != 'Unknown']
director_list = []
for directors in filtered_df['director'].dropna():
    if pd.notna(directors):
        # 拆分多个导演
        director_list.extend([d.strip() for d in directors.split(',')])

director_counts = pd.Series(director_list).value_counts().head(10)

plt.figure(figsize=(14, 8))
ax = director_counts.plot(kind='barh', color='#4CAF50', alpha=0.8)
plt.title('Netflix执导作品最多的前10位导演', fontsize=18, fontweight='bold', pad=20)
plt.xlabel('作品数量', fontsize=14)
plt.ylabel('导演', fontsize=14)
plt.grid(axis='x', linestyle='--', alpha=0.7)

for i, v in enumerate(director_counts.values):
    ax.text(v + 0.5, i, str(v), ha='left', va='center', fontweight='bold')

plt.tight_layout()
plt.show()
```

## 业务分析

1. 内容上架的热力图：构建一个透视表（Pivot Table），行索引为 month_added，列索引为year_added（取最近10年），值为内容的数量。使用seaborn绘制热力图，分析Netflix偏好在每年的几月份集中上架新内容。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')

df['year_added'] = df['date_added'].dt.year
df['month_added'] = df['date_added'].dt.month

current_year = pd.Timestamp.now().year
start_year = current_year - 9  
filtered_df = df[(df['year_added'] >= start_year) & (df['year_added'] <= current_year)]

pivot_table = filtered_df.pivot_table(
    values='show_id',
    index='month_added',
    columns='year_added',
    aggfunc='count',
    fill_value=0
)

plt.figure(figsize=(14, 8))
sns.heatmap(
    pivot_table,
    annot=True,
    fmt='d',
    cmap='YlGnBu',
    cbar_kws={'label': '内容数量'},
    linewidths=0.5
)

plt.title(f'Netflix内容上架热力图（{start_year}-{current_year}）', fontsize=18, fontweight='bold', pad=20)
plt.xlabel('上架年份', fontsize=14)
plt.ylabel('上架月份', fontsize=14)

plt.xticks(rotation=45)
plt.yticks([i+0.5 for i in range(12)], [str(i+1) for i in range(12)])

plt.tight_layout()
plt.show()

print("\n分析结论：")
print("-" * 40)
top_month = monthly_average.idxmax()
top_month_avg = monthly_average.max()
print(f"Netflix平均在上架最多的月份是：{int(top_month)}月（平均 {top_month_avg:.1f} 部内容）")
print("可通过热力图观察每年的具体上架趋势和季节性偏好")
```

2. 电影时长分布：仅筛选 type 为 "Movie" 的数据，使用 seaborn 的 histplot 或 kdeplot 绘制电影时长（duration_num）的分布曲线，并标出平均时长。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

movie_df = df[df['type'] == 'Movie']
if 'duration_num' not in movie_df.columns:
    movie_df['duration_num'] = movie_df['duration'].str.extract('(\d+)').astype(float)

average_duration = movie_df['duration_num'].mean()

print("电影时长分布分析：")
print("-" * 50)
print(f"总电影数量：{len(movie_df)}")
print(f"平均电影时长：{average_duration:.1f} 分钟")
print(f"最短电影时长：{movie_df['duration_num'].min()} 分钟")
print(f"最长电影时长：{movie_df['duration_num'].max()} 分钟")
print(f"电影时长中位数：{movie_df['duration_num'].median()} 分钟")
print("-" * 50)

plt.figure(figsize=(14, 8))
sns.histplot(
    data=movie_df,
    x='duration_num',
    bins=30,
    kde=True,
    color='#2196F3',
    edgecolor='black',
    alpha=0.7
)

plt.axvline(x=average_duration, color='red', linestyle='--', linewidth=2, label=f'平均时长: {average_duration:.1f}分钟')
plt.title('Netflix电影时长分布', fontsize=18, fontweight='bold', pad=20)
plt.xlabel('电影时长（分钟）', fontsize=14)
plt.ylabel('电影数量', fontsize=14)
plt.xlim(0, movie_df['duration_num'].max() + 30)
plt.grid(True, linestyle='--', alpha=0.7)
plt.legend(fontsize=12)

plt.text(average_duration + 5, plt.ylim()[1] * 0.8, 
         f'平均时长: {average_duration:.1f}分钟', 
         color='red', fontweight='bold', fontsize=12, 
         bbox=dict(facecolor='white', alpha=0.8, edgecolor='red', boxstyle='round,pad=0.5'))

plt.tight_layout()
plt.show()

# 分析结果
print("\n分析结论：")
print("-" * 40)
if average_duration < 90:
    print(f"Netflix电影平均时长较短（{average_duration:.1f}分钟），适合快速观看。")
elif average_duration < 120:
    print(f"Netflix电影平均时长适中（{average_duration:.1f}分钟），符合主流电影长度。")
else:
    print(f"Netflix电影平均时长较长（{average_duration:.1f}分钟），可能以剧情片或史诗片为主。")

# 统计不同时长区间的电影数量
duration_bins = [0, 60, 90, 120, 150, float('inf')]
bin_labels = ['0-60分钟', '61-90分钟', '91-120分钟', '121-150分钟', '150分钟以上']
movie_df['duration_range'] = pd.cut(movie_df['duration_num'], bins=duration_bins, labels=bin_labels)
duration_counts = movie_df['duration_range'].value_counts().sort_index()

print("\n各时长区间电影数量：")
print("-" * 40)
for duration_range, count in duration_counts.items():
    percentage = (count / len(movie_df)) * 100
    print(f"{duration_range:<15}：{count:<10} 部 ({percentage:.1f}%)")
```

3. 不同国家的题材偏好：选取内容最多的前 3 个国家（如 USA, India, UK），分别分析这三个国家排名前 5 的题材（listed_in），并尝试用子图（Subplots）展示对比。

```python
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

df['country'] = df['country'].str.split(', ')
df_exploded = df.explode('country')

country_counts = df_exploded['country'].value_counts()
top_3_countries = country_counts.head(3)

print("内容最多的前3个国家：")
print("-" * 50)
for country, count in top_3_countries.items():
    print(f"{country}: {count} 部内容")
print("-" * 50)

top_countries = top_3_countries.index.tolist()
df_exploded['listed_in'] = df_exploded['listed_in'].str.split(', ')
df_genres_exploded = df_exploded.explode('listed_in')

fig, axes = plt.subplots(1, 3, figsize=(20, 8), sharey=True)

for i, country in enumerate(top_countries):
    country_data = df_genres_exploded[df_genres_exploded['country'] == country]
    genre_counts = country_data['listed_in'].value_counts()
    top_5_genres = genre_counts.head(5)
    
    sns.barplot(
        x=top_5_genres.values,
        y=top_5_genres.index,
        ax=axes[i],
        palette='viridis'
    )
    
    axes[i].set_title(f'{country} 排名前5的题材', fontsize=16, fontweight='bold')
    axes[i].set_xlabel('内容数量', fontsize=14)
    
    for j, v in enumerate(top_5_genres.values):
        axes[i].text(v + 10, j, str(v), va='center', fontsize=12)

plt.tight_layout()
plt.subplots_adjust(wspace=0.1)


print("\n各国排名前5的题材详细数据：")
print("=" * 70)
for country in top_countries:
    country_data = df_genres_exploded[df_genres_exploded['country'] == country]
    genre_counts = country_data['listed_in'].value_counts()
    top_5_genres = genre_counts.head(5)
    
    print(f"\n{country}:")
    print("-" * 30)
    for genre, count in top_5_genres.items():
        percentage = (count / len(country_data)) * 100
        print(f"{genre:<40}：{count:<10} 部 ({percentage:.1f}%)")
```

4. 电视剧季度数分析：仅筛选 type 为 "TV Show" 的数据，统计拥有 "1 Season", "2 Seasons" ... 等不同季度数的剧集数量，绘制条形图。分析 Netflix 上的剧集是否大多是短命的（只有 1-2 季）。

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 设置中文字体
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# 读取清洗后的数据
input_path = './netflix_titles_cleaned.csv'
df = pd.read_csv(input_path)

# 筛选电视剧数据
tv_df = df[df['type'] == 'TV Show'].copy()

# 处理season信息，提取季度数字
if 'duration_num' not in tv_df.columns:
    tv_df['duration_num'] = tv_df['duration'].str.extract('(\d+)').astype(float)
    tv_df['season_count'] = tv_df['duration_num'].astype(int)
else:
    tv_df['season_count'] = tv_df['duration_num'].astype(int)

# 统计不同季度数的剧集数量
season_counts = tv_df['season_count'].value_counts().sort_index()

# 计算1-2季的剧集占比
short_run_series = season_counts.loc[1:2].sum()
total_series = len(tv_df)
short_run_percentage = (short_run_series / total_series) * 100

# 打印分析结果
print("电视剧季度数分析：")
print("=" * 50)
print(f"总剧集数量：{total_series}")
print(f"1-2季的剧集数量：{short_run_series}")
print(f"1-2季剧集占比：{short_run_percentage:.1f}%")
print("=" * 50)

print("\n各季度数剧集数量分布：")
print("-" * 40)
for season, count in season_counts.items():
    percentage = (count / total_series) * 100
    print(f"{season} {'季' if season == 1 else '季'}: {count} 部 ({percentage:.1f}%)")

# 绘制条形图
plt.figure(figsize=(16, 10))

# 由于季度数可能较多，我们只显示前20个季度数
top_seasons = season_counts.head(20)

bar_plot = sns.barplot(
    x=top_seasons.index,
    y=top_seasons.values,
    palette='magma'
)

# 设置标题和标签
plt.title('Netflix电视剧季度数分布', fontsize=20, fontweight='bold', pad=20)
plt.xlabel('季度数', fontsize=16)
plt.ylabel('剧集数量', fontsize=16)

# 添加数值标签
for i, v in enumerate(top_seasons.values):
    plt.text(i, v + 10, str(v), ha='center', fontsize=12)

# 添加分析结论的文本注释
plt.text(
    0.5, -0.15, 
    f"分析结论：Netflix上约{short_run_percentage:.1f}%的剧集只有1-2季，说明大多数剧集是短命的", 
    ha='center', 
    fontsize=14, 
    fontweight='bold',
    transform=plt.gca().transAxes
)

# 调整布局
plt.tight_layout()

# 保存图片
plt.savefig('./tv_show_season_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# 进一步分析：统计不同季度范围的剧集数量
season_bins = [0, 2, 5, 10, float('inf')]
bin_labels = ['1-2季', '3-5季', '6-10季', '10季以上']
tv_df['season_range'] = pd.cut(tv_df['season_count'], bins=season_bins, labels=bin_labels, right=False)
range_counts = tv_df['season_range'].value_counts().sort_index()

print("\n各季度范围剧集数量：")
print("-" * 40)
for season_range, count in range_counts.items():
    percentage = (count / total_series) * 100
    print(f"{season_range:<10}：{count:<10} 部 ({percentage:.1f}%)")
```

5. 演员与内容的关联：从cast 列中提取所有演员名字（需解决逗号分隔和列表展开的问题），统计出出现频率最高的10位演员。并用 seaborn绘制条形图，用颜色区分他们主要出演的是Movie还是TV Show（如果在两种类型都出现，归类为占比高的一方）。

```python
```

